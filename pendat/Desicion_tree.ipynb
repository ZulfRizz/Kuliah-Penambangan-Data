{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1dc41e6",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "## Apa itu Decision Tree?\n",
    "\n",
    "**Decision Tree (Pohon Keputusan)** adalah salah satu algoritma *machine learning* kategori *supervised learning* yang sangat populer karena intuisinya yang mudah dipahami. Algoritma ini memodelkan data dalam struktur seperti pohon, di mana setiap *node* internal merepresentasikan \"tes\" pada sebuah fitur, setiap cabang merepresentasikan hasil dari tes tersebut, dan setiap *leaf node* (daun) merepresentasikan label kelas.\n",
    "\n",
    "Tujuan utamanya adalah untuk membuat model yang dapat memprediksi nilai variabel target dengan mempelajari aturan keputusan sederhana yang diambil dari fitur data.\n",
    "\n",
    "* **Root Node**: Node paling atas yang mewakili seluruh dataset.\n",
    "* **Internal Node**: Node percabangan yang menguji sebuah fitur.\n",
    "* **Leaf Node**: Node terminal yang memberikan hasil akhir (kelas).\n",
    "\n",
    "---\n",
    "\n",
    "## Notasi Decision Tree\n",
    "\n",
    "Dalam konteks pohon keputusan, kita sering menggunakan notasi berikut:\n",
    "* **S**: Menyatakan himpunan data (dataset).\n",
    "* **A**: Mewakili sebuah atribut atau fitur (misalnya, 'Cuaca').\n",
    "* **v**: Salah satu nilai yang mungkin dari atribut A (misalnya, 'Cerah').\n",
    "* **$|S|$**: Jumlah sampel atau baris data dalam himpunan S.\n",
    "* **$S_v$**: Subset dari S di mana atribut A memiliki nilai v.\n",
    "* **$p_i$**: Proporsi dari kelas ke-i dalam sebuah himpunan data.\n",
    "\n",
    "---\n",
    "\n",
    "## Entropy \n",
    "\n",
    "**Entropy** adalah metrik yang digunakan untuk mengukur tingkat **ketidakmurnian (impurity)** atau ketidakpastian dalam sebuah himpunan data. Semakin tinggi nilai entropy, semakin tercampur label kelas di dalam himpunan data tersebut. Sesuai dengan notasi pada gambar Anda:\n",
    "\n",
    "Rumus matematis untuk Entropy adalah:\n",
    "$$ Entropy(S) = \\sum_{i=1}^{k} -p_i \\log_2(p_i) $$\n",
    "Di mana:\n",
    "* $k$ adalah jumlah total kelas.\n",
    "* $p_i$ adalah proporsi sampel yang termasuk dalam kelas *i* pada himpunan data $S$.\n",
    "\n",
    "---\n",
    "\n",
    "## Information Gain \n",
    "\n",
    "**Information Gain** mengukur penurunan entropy setelah data dipisahkan berdasarkan sebuah atribut. Atribut dengan Information Gain tertinggi akan dipilih sebagai pemisah. Sesuai dengan generalisasi pada gambar Anda:\n",
    "\n",
    "$$ Gain(S, A) = Entropy(S) - Entropy(S|A) $$\n",
    "\n",
    "Di mana $Entropy(S|A)$ adalah entropy bersyarat (rata-rata entropy setelah dipecah oleh atribut A), yang dihitung dengan:\n",
    "\n",
    "$$ Entropy(S|A) = \\sum_{v \\in \\text{Values(A)}} \\frac{|S_v|}{|S|} Entropy(S_v) $$\n",
    "Di mana:\n",
    "* $v$ adalah setiap nilai unik dari atribut A.\n",
    "* $S_v$ adalah subset data di mana atribut A memiliki nilai $v$.\n",
    "* $Entropy(S_v)$ adalah entropy dari subset $S_v$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971e66d",
   "metadata": {},
   "source": [
    "# 1. Perhitungan Manual: Entropy dan Information Gain\n",
    "\n",
    "## Dataset Contoh\n",
    "\n",
    "Kita akan menggunakan dataset sederhana yang sama: 15 baris, 2 fitur (`Cuaca`, `Suhu`), dan 3 kelas target (`Aktivitas`).\n",
    "\n",
    "| Cuaca | Suhu | Aktivitas |\n",
    "| :--- | :--- | :--- |\n",
    "| Cerah | Panas | Olahraga |\n",
    "| Cerah | Panas | Olahraga |\n",
    "| Cerah | Normal | Olahraga |\n",
    "| Cerah | Dingin | Santai |\n",
    "| Cerah | Normal | Santai |\n",
    "| Mendung | Panas | Kerja |\n",
    "| Mendung | Normal | Kerja |\n",
    "| Mendung | Dingin | Kerja |\n",
    "| Mendung | Panas | Santai |\n",
    "| Hujan | Normal | Santai |\n",
    "| Hujan | Dingin | Santai |\n",
    "| Hujan | Dingin | Kerja |\n",
    "| Hujan | Normal | Kerja |\n",
    "| Hujan | Normal | Kerja |\n",
    "| Hujan | Dingin | Santai |\n",
    "\n",
    "**Distribusi Kelas (Total 15 data):**\n",
    "* **Olahraga**: 3 ($p_1 = 3/15 = 0.2$)\n",
    "* **Santai**: 6 ($p_2 = 6/15 = 0.4$)\n",
    "* **Kerja**: 6 ($p_3 = 6/15 = 0.4$)\n",
    "\n",
    "---\n",
    "\n",
    "## Langkah 1: Hitung Entropy Awal (Entropy(S))\n",
    "\n",
    "$$ Entropy(S) = - (0.2 \\cdot \\log_2(0.2)) - (0.4 \\cdot \\log_2(0.4)) - (0.4 \\cdot \\log_2(0.4)) $$\n",
    "$$ Entropy(S) = - (0.2 \\cdot -2.3219) - (0.4 \\cdot -1.3219) - (0.4 \\cdot -1.3219) $$\n",
    "$$ Entropy(S) = 0.4644 + 0.5288 + 0.5288 = \\mathbf{1.522} $$\n",
    "\n",
    "---\n",
    "\n",
    "## Langkah 2: Hitung Information Gain untuk Setiap Fitur\n",
    "\n",
    "### A. Information Gain untuk Fitur `Cuaca`\n",
    "Entropy bersyarat untuk `Cuaca`, $Entropy(S|\\text{Cuaca})$:\n",
    "* $Entropy(\\text{Cerah}) = -(\\frac{2}{5}\\log_2\\frac{2}{5}) - (\\frac{3}{5}\\log_2\\frac{3}{5}) = 0.971$\n",
    "* $Entropy(\\text{Mendung}) = -(\\frac{1}{4}\\log_2\\frac{1}{4}) - (\\frac{3}{4}\\log_2\\frac{3}{4}) = 0.811$\n",
    "* $Entropy(\\text{Hujan}) = -(\\frac{3}{6}\\log_2\\frac{3}{6}) - (\\frac{3}{6}\\log_2\\frac{3}{6}) = 1.0$\n",
    "\n",
    "$$ Entropy(S|\\text{Cuaca}) = \\left(\\frac{5}{15} \\cdot 0.971\\right) + \\left(\\frac{4}{15} \\cdot 0.811\\right) + \\left(\\frac{6}{15} \\cdot 1.0\\right) $$\n",
    "$$ Entropy(S|\\text{Cuaca}) = 0.324 + 0.216 + 0.4 = 0.940 $$\n",
    "$$ Gain(S, \\text{Cuaca}) = Entropy(S) - Entropy(S|\\text{Cuaca}) = 1.522 - 0.940 = \\mathbf{0.582} $$\n",
    "\n",
    "### B. Information Gain untuk Fitur `Suhu`\n",
    "Entropy bersyarat untuk `Suhu`, $Entropy(S|\\text{Suhu})$:\n",
    "* $Entropy(\\text{Panas}) = -(\\frac{2}{4}\\log_2\\frac{2}{4}) - (\\frac{1}{4}\\log_2\\frac{1}{4}) - (\\frac{1}{4}\\log_2\\frac{1}{4}) = 1.5$\n",
    "* $Entropy(\\text{Normal}) = -(\\frac{1}{5}\\log_2\\frac{1}{5}) - (\\frac{2}{5}\\log_2\\frac{2}{5}) - (\\frac{2}{5}\\log_2\\frac{2}{5}) = 1.522$\n",
    "* $Entropy(\\text{Dingin}) = -(\\frac{3}{6}\\log_2\\frac{3}{6}) - (\\frac{3}{6}\\log_2\\frac{3}{6}) = 1.0$\n",
    "\n",
    "$$ Entropy(S|\\text{Suhu}) = \\left(\\frac{4}{15} \\cdot 1.5\\right) + \\left(\\frac{5}{15} \\cdot 1.522\\right) + \\left(\\frac{6}{15} \\cdot 1.0\\right) $$\n",
    "$$ Entropy(S|\\text{Suhu}) = 0.400 + 0.507 + 0.4 = 1.307 $$\n",
    "$$ Gain(S, \\text{Suhu}) = Entropy(S) - Entropy(S|\\text{Suhu}) = 1.522 - 1.307 = \\mathbf{0.215} $$\n",
    "\n",
    "---\n",
    "\n",
    "## Kesimpulan Perhitungan Manual\n",
    "\n",
    "Information Gain `Cuaca` (0.582) lebih tinggi daripada Information Gain `Suhu` (0.215). Oleh karena itu, fitur **`Cuaca`** akan dipilih sebagai **root node**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec25da",
   "metadata": {},
   "source": [
    "## Perhtiungan menggunakan Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e6ca8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
